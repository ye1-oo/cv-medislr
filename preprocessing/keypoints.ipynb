{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMRA16piVciXnlgmcyF4abJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e87240099d7f4402812c93c72b0376c4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5b1a8edf22004708a1375f1f01c5787b","IPY_MODEL_a187778972f941af9c2ce43657705c6f","IPY_MODEL_ad28ae32eefa49128ed247ef8928a58c"],"layout":"IPY_MODEL_86edee2cb9db44e79700961e0739fbee"}},"5b1a8edf22004708a1375f1f01c5787b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a88045972f84b33b00a476cf028b8ab","placeholder":"â€‹","style":"IPY_MODEL_4d84118ce65f4d3d9b17c82a1140fde8","value":"100%"}},"a187778972f941af9c2ce43657705c6f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_81e3f9aba74e4972a9ea1343f5236986","max":1097,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2835799e1d584322993fb8f885439125","value":1097}},"ad28ae32eefa49128ed247ef8928a58c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa9d260b13454ee881c9869338801401","placeholder":"â€‹","style":"IPY_MODEL_8c27e9462e274ff7b8ef1464872ee1cd","value":"â€‡1097/1097â€‡[2:50:46&lt;00:00,â€‡â€‡6.39s/it]"}},"86edee2cb9db44e79700961e0739fbee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a88045972f84b33b00a476cf028b8ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d84118ce65f4d3d9b17c82a1140fde8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81e3f9aba74e4972a9ea1343f5236986":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2835799e1d584322993fb8f885439125":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aa9d260b13454ee881c9869338801401":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c27e9462e274ff7b8ef1464872ee1cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["from pathlib import Path\n","import shutil\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","BASE_DIR = Path(\"/content/drive/MyDrive/preprocessing\")\n","\n","ROOT_NAMES = [\n","    \"Holistic_hands_frames\",\n","    \"Holistic_body_frames\",\n","    \"Holistic_full_frames\",\n","    \"Keypoints_json\",\n","]\n","\n","for name in ROOT_NAMES:\n","    root = BASE_DIR / name\n","    root.mkdir(parents=True, exist_ok=True)   # ë£¨íŠ¸ í´ë” ì—†ìœ¼ë©´ ìƒì„±\n","    print(f\"[ROOT] {root}\")\n","\n","    for pid in range(1, 11):\n","        d = root / str(pid)\n","\n","        # í´ë”ê°€ ì´ë¯¸ ìˆìœ¼ë©´ ì•ˆì˜ ë‚´ìš©ë§Œ ì‹¹ ë¹„ìš°ê³  ë‹¤ì‹œ ìƒì„±\n","        if d.exists():\n","            shutil.rmtree(d)\n","\n","        d.mkdir(parents=True, exist_ok=True)\n","        print(f\"  -> prepared: {d}\")\n","\n","print(\"âœ… ëª¨ë“  rootì— 1~10 í´ë” ìƒì„± / ì´ˆê¸°í™” ì™„ë£Œ\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EGBLw4JQq81z","executionInfo":{"status":"ok","timestamp":1763485032520,"user_tz":-540,"elapsed":27810,"user":{"displayName":"ë…¸ì¤€í˜","userId":"17692108505654888249"}},"outputId":"608851e5-bf05-403c-fb8a-3ab80743f4d0"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","[ROOT] /content/drive/MyDrive/preprocessing/Holistic_hands_frames\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_hands_frames/1\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_hands_frames/2\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_hands_frames/3\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_hands_frames/4\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_hands_frames/5\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_hands_frames/6\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_hands_frames/7\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_hands_frames/8\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_hands_frames/9\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_hands_frames/10\n","[ROOT] /content/drive/MyDrive/preprocessing/Holistic_body_frames\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_body_frames/1\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_body_frames/2\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_body_frames/3\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_body_frames/4\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_body_frames/5\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_body_frames/6\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_body_frames/7\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_body_frames/8\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_body_frames/9\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_body_frames/10\n","[ROOT] /content/drive/MyDrive/preprocessing/Holistic_full_frames\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_full_frames/1\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_full_frames/2\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_full_frames/3\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_full_frames/4\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_full_frames/5\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_full_frames/6\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_full_frames/7\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_full_frames/8\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_full_frames/9\n","  -> prepared: /content/drive/MyDrive/preprocessing/Holistic_full_frames/10\n","[ROOT] /content/drive/MyDrive/preprocessing/Keypoints_json\n","  -> prepared: /content/drive/MyDrive/preprocessing/Keypoints_json/1\n","  -> prepared: /content/drive/MyDrive/preprocessing/Keypoints_json/2\n","  -> prepared: /content/drive/MyDrive/preprocessing/Keypoints_json/3\n","  -> prepared: /content/drive/MyDrive/preprocessing/Keypoints_json/4\n","  -> prepared: /content/drive/MyDrive/preprocessing/Keypoints_json/5\n","  -> prepared: /content/drive/MyDrive/preprocessing/Keypoints_json/6\n","  -> prepared: /content/drive/MyDrive/preprocessing/Keypoints_json/7\n","  -> prepared: /content/drive/MyDrive/preprocessing/Keypoints_json/8\n","  -> prepared: /content/drive/MyDrive/preprocessing/Keypoints_json/9\n","  -> prepared: /content/drive/MyDrive/preprocessing/Keypoints_json/10\n","âœ… ëª¨ë“  rootì— 1~10 í´ë” ìƒì„± / ì´ˆê¸°í™” ì™„ë£Œ\n"]}]},{"cell_type":"code","source":["# ============================================\n","# 1) ê¸°ë³¸ ì„¸íŒ… & Mediapipe ì„¤ì¹˜/ë¡œë“œ\n","# ============================================\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!pip -q install mediapipe==0.10.14\n","\n","\n","from pathlib import Path\n","import os, cv2, json\n","import numpy as np\n","import mediapipe as mp\n","from tqdm.auto import tqdm\n","\n","# ğŸ”§ ê²½ë¡œ ì„¤ì • (ë„¤ êµ¬ì¡° ê¸°ì¤€)\n","BASE_DIR      = Path(\"/content/drive/MyDrive/preprocessing\")\n","CROPPED_DIR   = BASE_DIR / \"cropped_videos\"        # 22ê°œ ë‹¨ì–´ Ã— 10ëª… Ã— 5ê°ë„\n","HANDS_ROOT    = BASE_DIR / \"Holistic_hands_frames\"\n","BODY_ROOT     = BASE_DIR / \"Holistic_body_frames\"\n","FULL_ROOT     = BASE_DIR / \"Holistic_full_frames\"\n","JSON_ROOT     = BASE_DIR / \"Keypoints_json\"\n","\n","# ì‚¬ëŒ ID ë§¤í•‘: P01 â†’ \"1\", ..., P10 â†’ \"10\"\n","P_TO_ID = {f\"P{idx:02d}\": str(idx) for idx in range(1, 11)}\n","\n","IMG_SIZE   = 720   # í”„ë ˆì„ ìº”ë²„ìŠ¤ í¬ê¸° (ì •ì‚¬ê°, ì˜ˆì „ ì½”ë“œë‘ ë¹„ìŠ·í•˜ê²Œ í¬ê²Œ)\n","FRAME_STRIDE = 1   # ëª¨ë“  í”„ë ˆì„ ì‚¬ìš© (í•„ìš”í•˜ë©´ 2ë¡œ ì¤„ì—¬ì„œ ì†ë„â†‘)\n","\n","# Mediapipe ëª¨ë“ˆ\n","mp_holistic = mp.solutions.holistic\n","mp_hands    = mp.solutions.hands\n","mp_pose     = mp.solutions.pose\n","mp_fmesh    = mp.solutions.face_mesh\n","\n","HAND_CONNS = list(mp_hands.HAND_CONNECTIONS)\n","POSE_CONNS = list(mp_pose.POSE_CONNECTIONS)\n","FACEMESH_CONTOURS = list(mp_fmesh.FACEMESH_CONTOURS)   # ì–¼êµ´ ìœ¤ê³½ì„ ë§Œ ì‚¬ìš©\n","\n","# === ë¨¸ë¦¬(ì–¼êµ´) ì—†ëŠ” ë°”ë””ìš© ì„¤ì • ===\n","# Mediapipe Pose index ê¸°ì¤€: 0~10ì´ ì–¼êµ´/ë¨¸ë¦¬ ìª½ (nose, eye, ear, mouth ë“±)\n","HEAD_IDS = list(range(0, 11))  # 0~10\n","\n","# ëª¸í†µ/íŒ”/ë‹¤ë¦¬ ìœ„ì£¼ë¡œ ì“¸ landmark idë“¤ (ì–´ê¹¨~ë°œ, ë°œë)\n","BODY_ONLY_IDS = {\n","    11, 12, 13, 14, 15, 16,      # ì–´ê¹¨/íŒ”\n","    23, 24, 25, 26, 27, 28,      # ì—‰ë©ì´/ë¬´ë¦/ë°œëª©\n","    31, 32                       # ë°œë\n","}\n","\n","POSE_CONNS_BODY = [\n","    (a, b)\n","    for (a, b) in POSE_CONNS\n","    if a in BODY_ONLY_IDS and b in BODY_ONLY_IDS\n","]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fp-fcBQjrVUz","executionInfo":{"status":"ok","timestamp":1763485079171,"user_tz":-540,"elapsed":17473,"user":{"displayName":"ë…¸ì¤€í˜","userId":"17692108505654888249"}},"outputId":"7db18be3-1107-4dde-e878-fdaea2df0085"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\n","grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n","ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["# ============================================\n","# 2) í‚¤í¬ì¸íŠ¸ ë³€í™˜ & ê·¸ë¦¬ê¸° í—¬í¼\n","# ============================================\n","\n","def lm_to_arrays(lm_list, n_expected):\n","    \"\"\"Mediapipe landmark ë¦¬ìŠ¤íŠ¸ â†’ (x,y,z,vis) numpy ë°°ì—´ (ê¸¸ì´ n_expected, ì—†ìœ¼ë©´ NaN/0)\"\"\"\n","    if lm_list is None:\n","        xs = np.full(n_expected, np.nan)\n","        ys = np.full(n_expected, np.nan)\n","        zs = np.full(n_expected, np.nan)\n","        vs = np.zeros(n_expected)\n","        return xs, ys, zs, vs\n","\n","    xs = np.array([p.x for p in lm_list.landmark])\n","    ys = np.array([p.y for p in lm_list.landmark])\n","    zs = np.array([getattr(p, \"z\", 0.0) for p in lm_list.landmark])\n","    vs = np.ones(len(xs))\n","\n","    # ê¸¸ì´ ë³´ì • (ë¶€ì¡±í•˜ë©´ íŒ¨ë”©, ë§ìœ¼ë©´ ìë¥´ê¸°)\n","    if len(xs) < n_expected:\n","        pad = n_expected - len(xs)\n","        xs = np.pad(xs, (0, pad), constant_values=np.nan)\n","        ys = np.pad(ys, (0, pad), constant_values=np.nan)\n","        zs = np.pad(zs, (0, pad), constant_values=np.nan)\n","        vs = np.pad(vs, (0, pad), constant_values=0.0)\n","    elif len(xs) > n_expected:\n","        xs, ys, zs, vs = xs[:n_expected], ys[:n_expected], zs[:n_expected], vs[:n_expected]\n","\n","    return xs, ys, zs, vs\n","\n","\n","def arrays_to_json(xs, ys, zs, vs):\n","    \"\"\"(x,y,z,vis) ë°°ì—´ â†’ JSON-friendly ë¦¬ìŠ¤íŠ¸ (NaNì€ nullë¡œ)\"\"\"\n","    out = []\n","    for x, y, z, v in zip(xs, ys, zs, vs):\n","        if not np.isfinite(x) or not np.isfinite(y):\n","            out.append({\"x\": None, \"y\": None, \"z\": None, \"v\": float(v)})\n","        else:\n","            out.append({\"x\": float(x), \"y\": float(y), \"z\": float(z), \"v\": float(v)})\n","    return out\n","\n","\n","def draw_points_and_lines(canvas, xs, ys, vs, conns, color_line, color_dot,\n","                          r=2, thick=1, size=IMG_SIZE):\n","    \"\"\"ì •ê·œí™”(0~1) ì¢Œí‘œë¥¼ ìº”ë²„ìŠ¤ ìœ„ì— ìŠ¤ì¼ˆë ˆí†¤ìœ¼ë¡œ ê·¸ë¦¼\"\"\"\n","    def to_px(v): return int(v * size)\n","\n","    pts = [\n","        (to_px(xs[i]), to_px(ys[i]))\n","        if np.isfinite(xs[i]) and np.isfinite(ys[i]) else None\n","        for i in range(len(xs))\n","    ]\n","\n","    # ì„  ê·¸ë¦¬ê¸°\n","    for a, b in conns:\n","        if a < len(pts) and b < len(pts) and pts[a] and pts[b] and vs[a] > 0.5 and vs[b] > 0.5:\n","            cv2.line(canvas, pts[a], pts[b], color_line, thick, cv2.LINE_AA)\n","\n","    # ì  ê·¸ë¦¬ê¸°\n","    for i, p in enumerate(pts):\n","        if p and vs[i] > 0.5:\n","            cv2.circle(canvas, p, r, color_dot, -1, cv2.LINE_AA)"],"metadata":{"id":"o54ThI6jrVXh","executionInfo":{"status":"ok","timestamp":1763485092808,"user_tz":-540,"elapsed":35,"user":{"displayName":"ë…¸ì¤€í˜","userId":"17692108505654888249"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from pathlib import Path\n","from collections import Counter\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","CROPPED_DIR = Path(\"/content/drive/MyDrive/preprocessing/cropped_videos\")\n","\n","video_paths = sorted(CROPPED_DIR.rglob(\"*.mp4\"))\n","print(\"ì´ mp4 ê°œìˆ˜:\", len(video_paths))\n","\n","# ì–´ë–¤ ë‹¨ì–´ í´ë”ë“¤ì´ ì‹¤ì œë¡œ mp4ë¥¼ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸\n","word_names = [p.parent.parent.name for p in video_paths]\n","print(\"ë‹¨ì–´ í´ë” ì¢…ë¥˜:\", sorted(set(word_names)))\n","print()\n","\n","cnt = Counter(word_names)\n","for w, c in sorted(cnt.items()):\n","    print(f\"{w}: {c}ê°œ\")"],"metadata":{"id":"oQlckYgmX1D4","executionInfo":{"status":"aborted","timestamp":1763484980405,"user_tz":-540,"elapsed":4,"user":{"displayName":"ë…¸ì¤€í˜","userId":"17692108505654888249"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================\n","# 3) ëª¨ë“  í¬ë¡­ ì˜ìƒ ì²˜ë¦¬ (ì˜ìƒë‹¹ 16í”„ë ˆì„ ê³ ì •)\n","#    - hands / body / full ì´ë¯¸ì§€\n","#    - hands / body / full JSON\n","# ============================================\n","\n","N_FRAMES = 16  # í•œ ì˜ìƒë‹¹ ë§Œë“¤ê³  ì‹¶ì€ í”„ë ˆì„ ê°œìˆ˜\n","\n","video_paths = sorted(CROPPED_DIR.rglob(\"*.mp4\"))\n","print(\"ì´ ë¹„ë””ì˜¤ ê°œìˆ˜:\", len(video_paths))\n","\n","with mp_holistic.Holistic(\n","    static_image_mode=False,\n","    model_complexity=1,\n","    enable_segmentation=False,\n","    refine_face_landmarks=True,\n","    min_detection_confidence=0.5,\n","    min_tracking_confidence=0.5,\n",") as holistic:\n","\n","    for vpath in tqdm(video_paths):\n","        # ì˜ˆ: .../cropped_videos/WORD0029_ê²€ì‚¬/P01/xxxx.mp4\n","        word_folder   = vpath.parent.parent.name\n","        person_folder = vpath.parent.name\n","        file_stem     = vpath.stem\n","\n","        person_id = P_TO_ID.get(person_folder)\n","        if person_id is None:\n","            print(f\"[WARN] person id not found for {vpath}\")\n","            continue\n","\n","        cap = cv2.VideoCapture(str(vpath))\n","        if not cap.isOpened():\n","            print(f\"[WARN] ì—´ ìˆ˜ ì—†ìŒ: {vpath}\")\n","            continue\n","\n","        # ì´ ì˜ìƒì—ì„œ \"ìœ íš¨í•œ\" í”„ë ˆì„ë“¤ì„ ëª¨ì•„ë‘˜ ë¦¬ìŠ¤íŠ¸\n","        valid_frames = []  # ê° ì›ì†Œ: dict(... ì•„ë˜ ì°¸ê³  ...)\n","        frame_idx = 0\n","\n","        while True:\n","            ok, frame = cap.read()\n","            if not ok:\n","                break\n","\n","            # í•„ìš”í•˜ë©´ FRAME_STRIDEë¡œ ì†ë„ ì¡°ì ˆ (ì§€ê¸ˆì€ 1 â†’ ëª¨ë“  í”„ë ˆì„)\n","            if frame_idx % FRAME_STRIDE != 0:\n","                frame_idx += 1\n","                continue\n","\n","            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","            res = holistic.process(rgb)\n","\n","            # ---- í‚¤í¬ì¸íŠ¸ numpy ë°°ì—´ ìƒì„± ----\n","            fx, fy, fz, fv = lm_to_arrays(res.face_landmarks,      468)\n","            px, py, pz, pv = lm_to_arrays(res.pose_landmarks,       33)\n","            xL, yL, zL, vL = lm_to_arrays(res.left_hand_landmarks,  21)\n","            xR, yR, zR, vR = lm_to_arrays(res.right_hand_landmarks, 21)\n","\n","            # ì´ í”„ë ˆì„ì— ì•„ë¬´ í‚¤í¬ì¸íŠ¸ë„ ì—†ìœ¼ë©´ ìŠ¤í‚µ\n","            has_any = (\n","                np.any(fv > 0.5) or\n","                np.any(pv > 0.5) or\n","                np.any(vL > 0.5) or\n","                np.any(vR > 0.5)\n","            )\n","            if not has_any:\n","                frame_idx += 1\n","                continue\n","\n","            # ---- ìº”ë²„ìŠ¤ 3ê°œ ì¤€ë¹„ ----\n","            hands_img = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n","            body_img  = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n","            full_img  = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n","\n","            # ========= â‘  hands: ì†ë§Œ =========\n","            draw_points_and_lines(hands_img, xL, yL, vL, HAND_CONNS,\n","                                  (255,255,255), (255,255,255), r=2, thick=1)\n","            draw_points_and_lines(hands_img, xR, yR, vR, HAND_CONNS,\n","                                  (255,255,255), (255,255,255), r=2, thick=1)\n","\n","            # ========= â‘¡ body: ì–¼êµ´ ì—†ëŠ” ëª¸+ì† =========\n","            pv_body = pv.copy()\n","            pv_body[HEAD_IDS] = 0.0\n","            draw_points_and_lines(\n","                body_img,\n","                px, py, pv_body,\n","                POSE_CONNS_BODY,\n","                (255,180,80), (255,220,120),\n","                r=3, thick=3\n","            )\n","            draw_points_and_lines(body_img, xL, yL, vL, HAND_CONNS,\n","                                  (255,255,255), (255,255,255), r=2, thick=2)\n","            draw_points_and_lines(body_img, xR, yR, vR, HAND_CONNS,\n","                                  (255,255,255), (255,255,255), r=2, thick=2)\n","\n","            # ========= â‘¢ full: ì–¼êµ´+ëª¸+ì† =========\n","            draw_points_and_lines(full_img, fx, fy, fv, FACEMESH_CONTOURS,\n","                                  (200,200,200), (180,180,180), r=1, thick=1)\n","            draw_points_and_lines(full_img, px, py, pv, POSE_CONNS,\n","                                  (255,180,80), (255,220,120), r=3, thick=3)\n","            draw_points_and_lines(full_img, xL, yL, vL, HAND_CONNS,\n","                                  (255,255,255), (255,255,255), r=2, thick=2)\n","            draw_points_and_lines(full_img, xR, yR, vR, HAND_CONNS,\n","                                  (255,255,255), (255,255,255), r=2, thick=2)\n","\n","            # JSON ì¢Œí‘œ ë¯¸ë¦¬ ë§Œë“¤ì–´ ë‘ê¸°\n","            face_json = arrays_to_json(fx, fy, fz, fv)\n","            pose_json = arrays_to_json(px, py, pz, pv)\n","            left_json = arrays_to_json(xL, yL, zL, vL)\n","            right_json = arrays_to_json(xR, yR, zR, vR)\n","\n","            # ì´ í”„ë ˆì„ ì •ë³´ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥ (ë°”ë¡œ íŒŒì¼ë¡œ ì•ˆ ì“°ê³ )\n","            valid_frames.append({\n","                \"orig_frame_index\": int(frame_idx),\n","                \"hands_img\": hands_img,\n","                \"body_img\": body_img,\n","                \"full_img\": full_img,\n","                \"face_json\": face_json,\n","                \"pose_json\": pose_json,\n","                \"left_json\": left_json,\n","                \"right_json\": right_json,\n","            })\n","\n","            frame_idx += 1\n","\n","        cap.release()\n","\n","        # ì´ ì˜ìƒì—ì„œ ìœ íš¨ í”„ë ˆì„ì´ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ íŒ¨ìŠ¤\n","        n_valid = len(valid_frames)\n","        if n_valid == 0:\n","            print(f\"[INFO] no valid landmarks in video: {vpath}\")\n","            continue\n","\n","        # ---- ì—¬ê¸°ì„œ N_FRAMES(16)ê°œ ì¸ë±ìŠ¤ ì„ íƒ ----\n","        if n_valid >= N_FRAMES:\n","            # 0 ~ n_valid-1 ë²”ìœ„ì—ì„œ ê· ë“±í•˜ê²Œ 16ê°œ ë½‘ê¸°\n","            chosen_idx = np.linspace(0, n_valid - 1, N_FRAMES, dtype=int)\n","        else:\n","            # ìœ íš¨ í”„ë ˆì„ì´ 16ê°œ ë¯¸ë§Œì´ë©´ ë§ˆì§€ë§‰ í”„ë ˆì„ì„ ë°˜ë³µí•´ì„œ ì±„ìš°ê¸°\n","            base = np.arange(n_valid)\n","            pad  = np.full(N_FRAMES - n_valid, n_valid - 1)\n","            chosen_idx = np.concatenate([base, pad])\n","\n","        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì¤€ë¹„\n","        out_hands_dir = HANDS_ROOT / person_id\n","        out_body_dir  = BODY_ROOT / person_id\n","        out_full_dir  = FULL_ROOT / person_id\n","        json_dir      = JSON_ROOT / person_id\n","\n","        out_hands_dir.mkdir(parents=True, exist_ok=True)\n","        out_body_dir.mkdir(parents=True, exist_ok=True)\n","        out_full_dir.mkdir(parents=True, exist_ok=True)\n","        json_dir.mkdir(parents=True, exist_ok=True)\n","\n","        # ì„ íƒëœ 16ê°œ í”„ë ˆì„ë§Œ ì‹¤ì œ íŒŒì¼ë¡œ ì €ì¥\n","        for seq_i, idx in enumerate(chosen_idx):\n","            item = valid_frames[idx]\n","            orig_fidx = item[\"orig_frame_index\"]\n","\n","            # s00 ~ s15 : ì‹œí€€ìŠ¤ ë‚´ ìœ„ì¹˜\n","            base_name = f\"{word_folder}_{file_stem}_s{seq_i:02d}\"\n","\n","            # PNG ì €ì¥\n","            cv2.imwrite(str(out_hands_dir / f\"{base_name}.png\"), item[\"hands_img\"])\n","            cv2.imwrite(str(out_body_dir  / f\"{base_name}.png\"), item[\"body_img\"])\n","            cv2.imwrite(str(out_full_dir  / f\"{base_name}.png\"), item[\"full_img\"])\n","\n","            # ê³µí†µ ë©”íƒ€\n","            common_meta = {\n","                \"video_path\": str(vpath),\n","                \"word_folder\": word_folder,\n","                \"person_folder\": person_folder,\n","                \"person_id\": person_id,\n","                \"file_stem\": file_stem,\n","                \"frame_index\": int(orig_fidx),  # ì›ë˜ í”„ë ˆì„ ë²ˆí˜¸\n","                \"seq_index\": int(seq_i),        # ì‹œí€€ìŠ¤ ë‚´ ì¸ë±ìŠ¤(0~15)\n","                \"img_size\": int(IMG_SIZE),\n","            }\n","\n","            # hands JSON\n","            obj_hands = {\n","                **common_meta,\n","                \"mode\": \"hands\",\n","                \"face\": [],\n","                \"pose\": [],\n","                \"left_hand\": item[\"left_json\"],\n","                \"right_hand\": item[\"right_json\"],\n","            }\n","            with open(json_dir / f\"{base_name}_hands.json\", \"w\", encoding=\"utf-8\") as f:\n","                json.dump(obj_hands, f, ensure_ascii=False)\n","\n","            # body JSON\n","            obj_body = {\n","                **common_meta,\n","                \"mode\": \"body\",\n","                \"face\": [],\n","                \"pose\": item[\"pose_json\"],\n","                \"left_hand\": item[\"left_json\"],\n","                \"right_hand\": item[\"right_json\"],\n","            }\n","            with open(json_dir / f\"{base_name}_body.json\", \"w\", encoding=\"utf-8\") as f:\n","                json.dump(obj_body, f, ensure_ascii=False)\n","\n","            # full JSON\n","            obj_full = {\n","                **common_meta,\n","                \"mode\": \"full\",\n","                \"face\": item[\"face_json\"],\n","                \"pose\": item[\"pose_json\"],\n","                \"left_hand\": item[\"left_json\"],\n","                \"right_hand\": item[\"right_json\"],\n","            }\n","            with open(json_dir / f\"{base_name}_full.json\", \"w\", encoding=\"utf-8\") as f:\n","                json.dump(obj_full, f, ensure_ascii=False)\n","\n","print(\"\\nâœ… ëª¨ë“  í¬ë¡­ ì˜ìƒì— ëŒ€í•´ 'ê¸¸ì´ 16' ì‹œí€€ìŠ¤ë¡œ hands/body/full ì´ë¯¸ì§€ + JSON ìƒì„±\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162,"referenced_widgets":["e87240099d7f4402812c93c72b0376c4","5b1a8edf22004708a1375f1f01c5787b","a187778972f941af9c2ce43657705c6f","ad28ae32eefa49128ed247ef8928a58c","86edee2cb9db44e79700961e0739fbee","5a88045972f84b33b00a476cf028b8ab","4d84118ce65f4d3d9b17c82a1140fde8","81e3f9aba74e4972a9ea1343f5236986","2835799e1d584322993fb8f885439125","aa9d260b13454ee881c9869338801401","8c27e9462e274ff7b8ef1464872ee1cd"]},"id":"l44jGb1TdCW2","executionInfo":{"status":"ok","timestamp":1763495381924,"user_tz":-540,"elapsed":10283328,"user":{"displayName":"ë…¸ì¤€í˜","userId":"17692108505654888249"}},"outputId":"be7678fa-eca0-4007-8591-e78b08ca567f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["ì´ ë¹„ë””ì˜¤ ê°œìˆ˜: 1097\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1097 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e87240099d7f4402812c93c72b0376c4"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n","  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"]},{"output_type":"stream","name":"stdout","text":["\n","âœ… ëª¨ë“  í¬ë¡­ ì˜ìƒì— ëŒ€í•´ 'ê¸¸ì´ 16' ì‹œí€€ìŠ¤ë¡œ hands/body/full ì´ë¯¸ì§€ + JSON ìƒì„±\n"]}]}]}
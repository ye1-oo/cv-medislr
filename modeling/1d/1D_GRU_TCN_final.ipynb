{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "UymiogDy-pY2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NIzFx6DgyANF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54859987-1bbb-4983-cb7f-412eb822eb9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import json\n",
        "import random\n",
        "import re\n",
        "from typing import List, Dict, Any, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# =========================\n",
        "# 0. 기본 설정\n",
        "# =========================\n",
        "BASE_DIR = \"/content/drive/MyDrive/cv-medislr/data/preprocessed/keypoints\"\n",
        "\n",
        "CKPT_DIR  = \"/content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D\"   # weights-only 저장\n",
        "CACHE_DIR = \"/content/drive/MyDrive/cv-medislr/data/preprocessed/tensors/1D\"     # 전처리 캐시(X,y,split,meta) 저장\n",
        "\n",
        "os.makedirs(CKPT_DIR, exist_ok=True)\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "\n",
        "TARGET_LEN = 16\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 40\n",
        "LEARNING_RATE = 3e-4\n",
        "WEIGHT_DECAY = 1e-2\n",
        "LABEL_SMOOTHING = 0.1\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "TRAIN_RATIO = 0.7\n",
        "VAL_RATIO = 0.15\n",
        "TEST_RATIO = 0.15\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "if DEVICE == \"cuda\":\n",
        "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "\n",
        "# =========================\n",
        "# 1. 유틸 함수들\n",
        "# =========================\n",
        "EXPECTED_HAND = 21\n",
        "SEQ_GROUP_RE = re.compile(r\"(.*)_s(\\d+)_hands$\")\n",
        "\n",
        "def load_json(path: str) -> Dict[str, Any]:\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def get_landmark_array(lst: List[Dict[str, float]], expected_len: int) -> np.ndarray:\n",
        "    arr = np.zeros((expected_len, 4), dtype=np.float32)\n",
        "    for i, lm in enumerate(lst[:expected_len]):\n",
        "        arr[i, 0] = lm.get(\"x\", 0.0)\n",
        "        arr[i, 1] = lm.get(\"y\", 0.0)\n",
        "        arr[i, 2] = lm.get(\"z\", 0.0)\n",
        "        arr[i, 3] = lm.get(\"v\", 0.0)\n",
        "    return np.nan_to_num(arr, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "def resample_sequence(seq: np.ndarray, target_len: int) -> np.ndarray:\n",
        "    seq = np.nan_to_num(seq, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "    L = seq.shape[0]\n",
        "    if L == target_len:\n",
        "        return seq\n",
        "    if L <= 1:\n",
        "        return np.repeat(seq, target_len, axis=0)\n",
        "    idxs = np.linspace(0, L - 1, target_len)\n",
        "    idxs = np.round(idxs).astype(np.int32)\n",
        "    idxs = np.clip(idxs, 0, L - 1)\n",
        "    out = seq[idxs]\n",
        "    return np.nan_to_num(out, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "def add_velocity_feature(seq: np.ndarray) -> np.ndarray:\n",
        "    seq = np.nan_to_num(seq, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "    vel = np.diff(seq, axis=0, prepend=seq[0:1])\n",
        "    vel = np.nan_to_num(vel, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "    out = np.concatenate([seq, vel], axis=-1)  # (T, 2D)\n",
        "    return np.nan_to_num(out, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "# =========================\n",
        "# 2. 데이터 로딩 & 전처리 (HANDS ONLY)\n",
        "# =========================\n",
        "def collect_sequences(base_dir: str):\n",
        "    \"\"\"\n",
        "    base_dir 아래:\n",
        "        person_x / *_s00_hands.json ...\n",
        "    파일 그룹핑: (base_id, seg_idx) 로 묶고\n",
        "    seg_idx별 frame 평균 후 (L,42,4) 시퀀스 생성 (lh+rh)\n",
        "    \"\"\"\n",
        "    all_seq_arrays = []\n",
        "    all_labels = []\n",
        "\n",
        "    person_dirs = sorted([d for d in glob.glob(os.path.join(base_dir, \"*\")) if os.path.isdir(d)])\n",
        "    print(f\"Found person dirs: {person_dirs}\")\n",
        "\n",
        "    for p_dir in person_dirs:\n",
        "        person_name = os.path.basename(p_dir)\n",
        "        json_files = glob.glob(os.path.join(p_dir, \"*_hands.json\"))\n",
        "\n",
        "        groups = {}  # base_id -> seg_idx -> [paths]\n",
        "        for jf in json_files:\n",
        "            stem = os.path.splitext(os.path.basename(jf))[0]\n",
        "            m = SEQ_GROUP_RE.match(stem)\n",
        "            if not m:\n",
        "                continue\n",
        "            base_id, seg_str = m.groups()\n",
        "            seg_idx = int(seg_str)\n",
        "            groups.setdefault(base_id, {}).setdefault(seg_idx, []).append(jf)\n",
        "\n",
        "        print(f\"[Person {person_name}] #base sequences: {len(groups)}\")\n",
        "\n",
        "        for base_id, seg_dict in groups.items():\n",
        "            segment_features = []\n",
        "            label_word = None\n",
        "\n",
        "            for seg_idx in sorted(seg_dict.keys()):\n",
        "                seg_jsons = sorted(seg_dict[seg_idx])\n",
        "                frame_kpts_list = []\n",
        "\n",
        "                for jf in seg_jsons:\n",
        "                    data = load_json(jf)\n",
        "                    if label_word is None:\n",
        "                        label_word = data.get(\"word_folder\", \"UNKNOWN\")\n",
        "\n",
        "                    lh = get_landmark_array(data.get(\"left_hand\", []), EXPECTED_HAND)\n",
        "                    rh = get_landmark_array(data.get(\"right_hand\", []), EXPECTED_HAND)\n",
        "\n",
        "                    frame_kpts = np.concatenate([lh, rh], axis=0)  # (42,4)  ✅ hands only\n",
        "                    frame_kpts = np.nan_to_num(frame_kpts, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "                    frame_kpts_list.append(frame_kpts)\n",
        "\n",
        "                if not frame_kpts_list:\n",
        "                    continue\n",
        "\n",
        "                # seg_idx 내 frame 평균 -> (42,4)\n",
        "                seg_arr = np.stack(frame_kpts_list, axis=0).mean(axis=0)\n",
        "                seg_arr = np.nan_to_num(seg_arr, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "                segment_features.append(seg_arr)\n",
        "\n",
        "            if not segment_features:\n",
        "                continue\n",
        "\n",
        "            # (L,42,4)\n",
        "            seq_arr = np.stack(segment_features, axis=0)\n",
        "            seq_arr = np.nan_to_num(seq_arr, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "            all_seq_arrays.append(seq_arr)\n",
        "            all_labels.append(label_word if label_word is not None else \"UNKNOWN\")\n",
        "\n",
        "    print(f\"Total sequences (base_id level): {len(all_seq_arrays)}\")\n",
        "    return all_seq_arrays, all_labels\n",
        "\n",
        "def build_label_mapping(labels: List[str]) -> Dict[str, int]:\n",
        "    uniq = sorted(list(set(labels)))\n",
        "    label2idx = {lab: i for i, lab in enumerate(uniq)}\n",
        "    print(\"Label mapping:\")\n",
        "    for k, v in label2idx.items():\n",
        "        print(f\"  {k} -> {v}\")\n",
        "    return label2idx\n",
        "\n",
        "def prepare_dataset(base_dir: str, target_len: int):\n",
        "    \"\"\"\n",
        "    hands-only:\n",
        "    (L,42,4) -> flatten (L,168) -> resample (T,168) -> +velocity (T,336)\n",
        "    \"\"\"\n",
        "    raw_seqs, raw_labels = collect_sequences(base_dir)\n",
        "    label2idx = build_label_mapping(raw_labels)\n",
        "\n",
        "    X_list = []\n",
        "    y_list = []\n",
        "\n",
        "    for seq_arr, lab in zip(raw_seqs, raw_labels):\n",
        "        L, J, C = seq_arr.shape      # (L,42,4)\n",
        "        seq_flat = seq_arr.reshape(L, J * C)  # (L,168)\n",
        "        seq_flat = np.nan_to_num(seq_flat, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "        seq_resampled = resample_sequence(seq_flat, target_len)  # (T,168)\n",
        "        seq_with_vel = add_velocity_feature(seq_resampled)       # (T,336)\n",
        "        seq_with_vel = np.nan_to_num(seq_with_vel, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "        X_list.append(seq_with_vel.astype(np.float32))\n",
        "        y_list.append(label2idx[lab])\n",
        "\n",
        "    X = np.stack(X_list, axis=0).astype(np.float32)  # (N,T,D)\n",
        "    y = np.array(y_list, dtype=np.int64)             # (N,)\n",
        "\n",
        "    input_dim = int(X.shape[-1])\n",
        "    num_classes = int(len(label2idx))\n",
        "    meta = {\n",
        "        \"label2idx\": label2idx,\n",
        "        \"num_classes\": num_classes,\n",
        "        \"input_dim\": input_dim,\n",
        "        \"target_len\": target_len,\n",
        "        \"seed\": RANDOM_SEED,\n",
        "        \"ratios\": {\"train\": TRAIN_RATIO, \"val\": VAL_RATIO, \"test\": TEST_RATIO},\n",
        "        \"mode\": \"hands_only\",\n",
        "        \"landmarks\": {\"left_hand\": 21, \"right_hand\": 21},\n",
        "        \"per_landmark_dim\": 4\n",
        "    }\n",
        "    print(f\"Final input dim D = {input_dim}, num_classes = {num_classes}\")\n",
        "    return X, y, meta\n",
        "\n",
        "def compute_global_stats_from_array(X: np.ndarray, train_idx: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    X: (N,T,D)\n",
        "    train_idx로만 mean/std 계산 (D,)\n",
        "    \"\"\"\n",
        "    train_data = X[train_idx]                   # (Ntr,T,D)\n",
        "    flat = train_data.reshape(-1, X.shape[-1])  # (Ntr*T, D)\n",
        "    flat = np.nan_to_num(flat, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "    mean = flat.mean(axis=0).astype(np.float32)\n",
        "    std = (flat.std(axis=0) + 1e-6).astype(np.float32)\n",
        "    mean = np.nan_to_num(mean, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "    std = np.nan_to_num(std, nan=1.0, posinf=1.0, neginf=1.0)\n",
        "    return mean, std\n",
        "\n",
        "# =========================\n",
        "# 2.5 전처리 캐시 저장/로드\n",
        "# =========================\n",
        "def cache_paths():\n",
        "    data_npz = os.path.join(CACHE_DIR, f\"data_HANDS_T{TARGET_LEN}_seed{RANDOM_SEED}.npz\")\n",
        "    meta_json = os.path.join(CACHE_DIR, f\"meta_HANDS_T{TARGET_LEN}_seed{RANDOM_SEED}.json\")\n",
        "    split_npz = os.path.join(CACHE_DIR, f\"split_HANDS_T{TARGET_LEN}_seed{RANDOM_SEED}.npz\")\n",
        "    return data_npz, meta_json, split_npz\n",
        "\n",
        "def build_or_load_cache():\n",
        "    data_npz, meta_json, split_npz = cache_paths()\n",
        "\n",
        "    # 1) 캐시 존재 시 로드\n",
        "    if os.path.exists(data_npz) and os.path.exists(meta_json) and os.path.exists(split_npz):\n",
        "        print(f\"✅ Load cached preprocessing: {data_npz}\")\n",
        "        pack = np.load(data_npz)\n",
        "        X = pack[\"X\"].astype(np.float32)\n",
        "        y = pack[\"y\"].astype(np.int64)\n",
        "\n",
        "        with open(meta_json, \"r\", encoding=\"utf-8\") as f:\n",
        "            meta = json.load(f)\n",
        "\n",
        "        split = np.load(split_npz)\n",
        "        train_idx = split[\"train_idx\"].astype(np.int64)\n",
        "        val_idx   = split[\"val_idx\"].astype(np.int64)\n",
        "        test_idx  = split[\"test_idx\"].astype(np.int64)\n",
        "        return X, y, meta, train_idx, val_idx, test_idx\n",
        "\n",
        "    # 2) 없으면 전처리 -> 저장\n",
        "    print(\"⏳ Cache not found. Running preprocessing once and saving cache...\")\n",
        "    X, y, meta = prepare_dataset(BASE_DIR, TARGET_LEN)\n",
        "\n",
        "    num_samples = len(X)\n",
        "    rng = random.Random(RANDOM_SEED)\n",
        "    indices = list(range(num_samples))\n",
        "    rng.shuffle(indices)\n",
        "\n",
        "    n_train = int(num_samples * TRAIN_RATIO)\n",
        "    n_val   = int(num_samples * VAL_RATIO)\n",
        "\n",
        "    train_idx = np.array(indices[:n_train], dtype=np.int64)\n",
        "    val_idx   = np.array(indices[n_train:n_train + n_val], dtype=np.int64)\n",
        "    test_idx  = np.array(indices[n_train + n_val:], dtype=np.int64)\n",
        "\n",
        "    np.savez_compressed(data_npz, X=X, y=y)\n",
        "    with open(meta_json, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(meta, f, ensure_ascii=False, indent=2)\n",
        "    np.savez_compressed(split_npz, train_idx=train_idx, val_idx=val_idx, test_idx=test_idx)\n",
        "\n",
        "    print(f\"✅ Saved cache: {data_npz}\")\n",
        "    print(f\"✅ Saved meta : {meta_json}\")\n",
        "    print(f\"✅ Saved split: {split_npz}\")\n",
        "    return X, y, meta, train_idx, val_idx, test_idx\n",
        "\n",
        "# =========================\n",
        "# 3. Dataset & Augmentation (캐시 기반)\n",
        "# =========================\n",
        "def augment_seq_tensor(seq: torch.Tensor) -> torch.Tensor:\n",
        "    T, D = seq.shape\n",
        "    if random.random() < 0.5:\n",
        "        scale = random.uniform(0.95, 1.05)\n",
        "        seq = seq * scale\n",
        "    if random.random() < 0.5 and T > 8:\n",
        "        cut = random.randint(0, 2)\n",
        "        if cut > 0:\n",
        "            seq_short = seq[cut:]\n",
        "            pad = seq_short[-1:].repeat(cut, 1)\n",
        "            seq = torch.cat([seq_short, pad], dim=0)\n",
        "    return seq\n",
        "\n",
        "class CachedSequenceDataset(Dataset):\n",
        "    \"\"\"\n",
        "    X: (N,T,D) numpy\n",
        "    y: (N,) numpy\n",
        "    indices: (K,) numpy\n",
        "    mean/std: (D,) numpy\n",
        "    \"\"\"\n",
        "    def __init__(self, X: np.ndarray, y: np.ndarray, indices: np.ndarray,\n",
        "                 mean: np.ndarray, std: np.ndarray, augment: bool):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.indices = indices\n",
        "        self.augment = augment\n",
        "        self.mean = torch.from_numpy(mean).float()\n",
        "        self.std  = torch.from_numpy(std).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        idx = int(self.indices[i])\n",
        "        seq = torch.from_numpy(self.X[idx]).float()  # (T,D)\n",
        "        label = int(self.y[idx])\n",
        "\n",
        "        seq = (seq - self.mean) / self.std\n",
        "\n",
        "        if self.augment:\n",
        "            if random.random() < 0.7:\n",
        "                seq = seq + torch.randn_like(seq) * 0.01\n",
        "            if random.random() < 0.5:\n",
        "                shift = random.randint(-3, 3)\n",
        "                if shift != 0:\n",
        "                    seq = torch.roll(seq, shifts=shift, dims=0)\n",
        "            seq = augment_seq_tensor(seq)\n",
        "\n",
        "        return seq, label\n",
        "\n",
        "# =========================\n",
        "# 4. 모델들\n",
        "# =========================\n",
        "class GRUClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes, hidden_dim=256, num_layers=2, bidirectional=True, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=input_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional,\n",
        "            dropout=dropout if num_layers > 1 else 0.0,\n",
        "        )\n",
        "        out_dim = hidden_dim * (2 if bidirectional else 1)\n",
        "        self.attn_fc = nn.Linear(out_dim, 1)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.LayerNorm(out_dim),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(out_dim, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.gru(x)\n",
        "        out = torch.nan_to_num(out, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "        w = torch.softmax(self.attn_fc(out), dim=1)\n",
        "        w = torch.nan_to_num(w, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "        feat = (w * out).sum(dim=1)\n",
        "        return self.head(feat)\n",
        "\n",
        "class TemporalConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, dilation=1, dropout=0.2):\n",
        "        super().__init__()\n",
        "        padding = ((kernel_size - 1) * dilation) // 2\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, padding=padding, dilation=dilation)\n",
        "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=padding, dilation=dilation)\n",
        "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
        "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.dropout(self.relu(self.bn1(self.conv1(x))))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        if self.downsample is not None:\n",
        "            x = self.downsample(x)\n",
        "        return self.relu(out + x)\n",
        "\n",
        "class AttnPool1d(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(in_channels, 1)\n",
        "\n",
        "    def forward(self, x):  # (B,C,T)\n",
        "        x_perm = x.transpose(1, 2)  # (B,T,C)\n",
        "        scores = self.attn(x_perm).squeeze(-1)     # (B,T)\n",
        "        weights = torch.softmax(scores, dim=-1)    # (B,T)\n",
        "        pooled = torch.bmm(weights.unsqueeze(1), x_perm)  # (B,1,C)\n",
        "        return pooled.squeeze(1)  # (B,C)\n",
        "\n",
        "class TCNClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes, hidden_channels=256):\n",
        "        super().__init__()\n",
        "        self.input_proj = nn.Linear(input_dim, hidden_channels)\n",
        "        self.tcn = nn.Sequential(\n",
        "            TemporalConvBlock(hidden_channels, hidden_channels, kernel_size=3, dilation=1),\n",
        "            TemporalConvBlock(hidden_channels, hidden_channels, kernel_size=3, dilation=2),\n",
        "            TemporalConvBlock(hidden_channels, hidden_channels, kernel_size=3, dilation=4),\n",
        "        )\n",
        "        self.pool = AttnPool1d(hidden_channels)\n",
        "        self.fc = nn.Linear(hidden_channels, num_classes)\n",
        "\n",
        "    def forward(self, x):  # (B,T,D)\n",
        "        x = self.input_proj(x)  # (B,T,C)\n",
        "        x = x.transpose(1, 2)   # (B,C,T)\n",
        "        x = self.tcn(x)         # (B,C,T)\n",
        "        x = self.pool(x)        # (B,C)\n",
        "        return self.fc(x)       # (B,num_classes)\n",
        "\n",
        "# =========================\n",
        "# 5. 학습/평가\n",
        "# =========================\n",
        "def run_epoch(model, loader, optimizer=None, criterion=None):\n",
        "    if optimizer is None:\n",
        "        model.eval()\n",
        "    else:\n",
        "        model.train()\n",
        "\n",
        "    total_loss, total_correct, total_count = 0.0, 0, 0\n",
        "\n",
        "    for seq, label in loader:\n",
        "        seq = seq.to(DEVICE)\n",
        "        label = label.to(DEVICE)\n",
        "\n",
        "        if optimizer is not None:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        logits = model(seq)\n",
        "        loss = criterion(logits, label)\n",
        "\n",
        "        if optimizer is not None:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * seq.size(0)\n",
        "        pred = torch.argmax(logits, dim=1)\n",
        "        total_correct += (pred == label).sum().item()\n",
        "        total_count += seq.size(0)\n",
        "\n",
        "    return total_loss / total_count, total_correct / total_count\n",
        "\n",
        "# =========================\n",
        "# 6. 저장/로드 (weights-only)\n",
        "# =========================\n",
        "def model_artifact_paths(model_name: str):\n",
        "    w_path    = os.path.join(CKPT_DIR, f\"{model_name}_best.pt\")          # ✅ weights-only\n",
        "    norm_path = os.path.join(CKPT_DIR, f\"{model_name}_norm.npz\")         # ✅ mean/std\n",
        "    meta_path = os.path.join(CKPT_DIR, f\"{model_name}_meta.json\")        # ✅ label2idx + cfg\n",
        "    return w_path, norm_path, meta_path\n",
        "\n",
        "def save_artifacts(model_name: str, model: nn.Module,\n",
        "                   train_mean: np.ndarray, train_std: np.ndarray,\n",
        "                   meta: dict, model_cfg: dict):\n",
        "    w_path, norm_path, meta_path = model_artifact_paths(model_name)\n",
        "\n",
        "    # 1) weights-only\n",
        "    torch.save(model.state_dict(), w_path)\n",
        "\n",
        "    # 2) norm\n",
        "    np.savez_compressed(norm_path, mean=train_mean.astype(np.float32), std=train_std.astype(np.float32))\n",
        "\n",
        "    # 3) meta\n",
        "    meta_out = {\n",
        "        \"label2idx\": meta[\"label2idx\"],\n",
        "        \"num_classes\": int(meta[\"num_classes\"]),\n",
        "        \"input_dim\": int(meta[\"input_dim\"]),\n",
        "        \"target_len\": int(meta[\"target_len\"]),\n",
        "        \"seed\": int(meta[\"seed\"]),\n",
        "        \"model_name\": model_name,\n",
        "        \"model_cfg\": model_cfg,\n",
        "        \"mode\": meta.get(\"mode\", \"hands_only\"),\n",
        "    }\n",
        "    with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(meta_out, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"✅ Saved weights-only: {w_path}\")\n",
        "    print(f\"✅ Saved norm       : {norm_path}\")\n",
        "    print(f\"✅ Saved meta       : {meta_path}\")\n",
        "\n",
        "def load_weights_only(w_path: str, model: nn.Module):\n",
        "    state = torch.load(w_path, map_location=DEVICE)  # state_dict only -> 안전\n",
        "    model.load_state_dict(state)\n",
        "    model.eval()\n",
        "\n",
        "# =========================\n",
        "# 7. 모델별 학습\n",
        "# =========================\n",
        "def train_one(model_name: str, X: np.ndarray, y: np.ndarray, meta: dict,\n",
        "              train_idx: np.ndarray, val_idx: np.ndarray, test_idx: np.ndarray):\n",
        "\n",
        "    input_dim = int(meta[\"input_dim\"])\n",
        "    num_classes = int(meta[\"num_classes\"])\n",
        "\n",
        "    # train 기준 mean/std\n",
        "    train_mean, train_std = compute_global_stats_from_array(X, train_idx)\n",
        "\n",
        "    train_dataset = CachedSequenceDataset(X, y, train_idx, train_mean, train_std, augment=True)\n",
        "    val_dataset   = CachedSequenceDataset(X, y, val_idx,   train_mean, train_std, augment=False)\n",
        "    test_dataset  = CachedSequenceDataset(X, y, test_idx,  train_mean, train_std, augment=False)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  num_workers=0)\n",
        "    val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "    test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "    if model_name == \"gru\":\n",
        "        model_cfg = {\"hidden_dim\": 256, \"num_layers\": 2, \"bidirectional\": True, \"dropout\": 0.2}\n",
        "        model = GRUClassifier(input_dim=input_dim, num_classes=num_classes, **model_cfg).to(DEVICE)\n",
        "    elif model_name == \"tcn\":\n",
        "        model_cfg = {\"hidden_channels\": 256}\n",
        "        model = TCNClassifier(input_dim=input_dim, num_classes=num_classes, **model_cfg).to(DEVICE)\n",
        "    else:\n",
        "        raise ValueError(\"model_name must be 'gru' or 'tcn'\")\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTHING)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=3)\n",
        "\n",
        "    best_val_acc = -1.0\n",
        "    best_w_path, _, _ = model_artifact_paths(model_name)\n",
        "\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        train_loss, train_acc = run_epoch(model, train_loader, optimizer, criterion)\n",
        "        val_loss, val_acc     = run_epoch(model, val_loader, optimizer=None, criterion=criterion)\n",
        "\n",
        "        print(f\"[{model_name.upper()}][Epoch {epoch:02d}] \"\n",
        "              f\"train_loss={train_loss:.4f}, train_acc={train_acc:.3f}, \"\n",
        "              f\"val_loss={val_loss:.4f}, val_acc={val_acc:.3f}\")\n",
        "\n",
        "        scheduler.step(val_acc)\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            save_artifacts(model_name, model, train_mean, train_std, meta, model_cfg)\n",
        "\n",
        "    # best weights 로드 후 test\n",
        "    load_weights_only(best_w_path, model)\n",
        "    test_loss, test_acc = run_epoch(model, test_loader, optimizer=None, criterion=criterion)\n",
        "\n",
        "    print(f\"\\n[{model_name.upper()}][Final] Best val_acc={best_val_acc:.3f}\")\n",
        "    print(f\"[{model_name.upper()}][Final] Test loss={test_loss:.4f}, Test acc={test_acc:.3f}\")\n",
        "    print(f\"✅ Best weights at: {best_w_path}\\n\")\n",
        "\n",
        "# =========================\n",
        "# 8. 메인\n",
        "# =========================\n",
        "def main():\n",
        "    X, y, meta, train_idx, val_idx, test_idx = build_or_load_cache()\n",
        "    train_one(\"gru\", X, y, meta, train_idx, val_idx, test_idx)\n",
        "    train_one(\"tcn\", X, y, meta, train_idx, val_idx, test_idx)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTEiYqCzeOOO",
        "outputId": "6af7e6d1-32db-461d-db6f-6c4cdb2fea61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "⏳ Cache not found. Running preprocessing once and saving cache...\n",
            "Found person dirs: ['/content/drive/MyDrive/cv-medislr/data/preprocessed/keypoints/1', '/content/drive/MyDrive/cv-medislr/data/preprocessed/keypoints/10', '/content/drive/MyDrive/cv-medislr/data/preprocessed/keypoints/2', '/content/drive/MyDrive/cv-medislr/data/preprocessed/keypoints/3', '/content/drive/MyDrive/cv-medislr/data/preprocessed/keypoints/4', '/content/drive/MyDrive/cv-medislr/data/preprocessed/keypoints/5', '/content/drive/MyDrive/cv-medislr/data/preprocessed/keypoints/6', '/content/drive/MyDrive/cv-medislr/data/preprocessed/keypoints/7', '/content/drive/MyDrive/cv-medislr/data/preprocessed/keypoints/8', '/content/drive/MyDrive/cv-medislr/data/preprocessed/keypoints/9']\n",
            "[Person 1] #base sequences: 107\n",
            "[Person 10] #base sequences: 110\n",
            "[Person 2] #base sequences: 110\n",
            "[Person 3] #base sequences: 110\n",
            "[Person 4] #base sequences: 110\n",
            "[Person 5] #base sequences: 110\n",
            "[Person 6] #base sequences: 110\n",
            "[Person 7] #base sequences: 110\n",
            "[Person 8] #base sequences: 110\n",
            "[Person 9] #base sequences: 110\n",
            "Total sequences (base_id level): 1097\n",
            "Label mapping:\n",
            "  WORD0029_검사 -> 0\n",
            "  WORD0033_당뇨병 -> 1\n",
            "  WORD0036_면역 -> 2\n",
            "  WORD0037_감기 -> 3\n",
            "  WORD0039_변비 -> 4\n",
            "  WORD0040_병명 -> 5\n",
            "  WORD0041_보건소 -> 6\n",
            "  WORD0042_불면증 -> 7\n",
            "  WORD0046_설사 -> 8\n",
            "  WORD0062_진단서 -> 9\n",
            "  WORD0064_치료 -> 10\n",
            "  WORD0065_치료법 -> 11\n",
            "  WORD0163_의사 -> 12\n",
            "  WORD0187_간호사 -> 13\n",
            "  WORD0400_정밀검사 -> 14\n",
            "  WORD0572_환자실 -> 15\n",
            "  WORD0689_통증 -> 16\n",
            "  WORD0885_치료제 -> 17\n",
            "  WORD1115_건강 -> 18\n",
            "  WORD1129_검사 -> 19\n",
            "  WORD1158_피곤하다 -> 20\n",
            "  WORD1496_병원 -> 21\n",
            "Final input dim D = 336, num_classes = 22\n",
            "✅ Saved cache: /content/drive/MyDrive/cv-medislr/data/preprocessed/cache_1/1D/data_HANDS_T16_seed42.npz\n",
            "✅ Saved meta : /content/drive/MyDrive/cv-medislr/data/preprocessed/cache_1/1D/meta_HANDS_T16_seed42.json\n",
            "✅ Saved split: /content/drive/MyDrive/cv-medislr/data/preprocessed/cache_1/1D/split_HANDS_T16_seed42.npz\n",
            "[GRU][Epoch 01] train_loss=2.4303, train_acc=0.348, val_loss=1.9158, val_acc=0.500\n",
            "✅ Saved weights-only: /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_best.pt\n",
            "✅ Saved norm       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_norm.npz\n",
            "✅ Saved meta       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_meta.json\n",
            "[GRU][Epoch 02] train_loss=1.6990, train_acc=0.641, val_loss=1.5642, val_acc=0.677\n",
            "✅ Saved weights-only: /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_best.pt\n",
            "✅ Saved norm       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_norm.npz\n",
            "✅ Saved meta       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_meta.json\n",
            "[GRU][Epoch 03] train_loss=1.4281, train_acc=0.729, val_loss=1.4060, val_acc=0.744\n",
            "✅ Saved weights-only: /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_best.pt\n",
            "✅ Saved norm       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_norm.npz\n",
            "✅ Saved meta       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_meta.json\n",
            "[GRU][Epoch 04] train_loss=1.2611, train_acc=0.795, val_loss=1.2866, val_acc=0.762\n",
            "✅ Saved weights-only: /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_best.pt\n",
            "✅ Saved norm       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_norm.npz\n",
            "✅ Saved meta       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_meta.json\n",
            "[GRU][Epoch 05] train_loss=1.1602, train_acc=0.849, val_loss=1.1971, val_acc=0.817\n",
            "✅ Saved weights-only: /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_best.pt\n",
            "✅ Saved norm       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_norm.npz\n",
            "✅ Saved meta       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_meta.json\n",
            "[GRU][Epoch 06] train_loss=1.0507, train_acc=0.889, val_loss=1.1479, val_acc=0.866\n",
            "✅ Saved weights-only: /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_best.pt\n",
            "✅ Saved norm       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_norm.npz\n",
            "✅ Saved meta       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_meta.json\n",
            "[GRU][Epoch 07] train_loss=0.9892, train_acc=0.906, val_loss=1.0909, val_acc=0.854\n",
            "[GRU][Epoch 08] train_loss=0.9236, train_acc=0.931, val_loss=1.0710, val_acc=0.854\n",
            "[GRU][Epoch 09] train_loss=0.8986, train_acc=0.944, val_loss=1.0826, val_acc=0.829\n",
            "[GRU][Epoch 10] train_loss=0.8490, train_acc=0.954, val_loss=1.0447, val_acc=0.890\n",
            "✅ Saved weights-only: /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_best.pt\n",
            "✅ Saved norm       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_norm.npz\n",
            "✅ Saved meta       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_meta.json\n",
            "[GRU][Epoch 11] train_loss=0.8389, train_acc=0.958, val_loss=1.0235, val_acc=0.884\n",
            "[GRU][Epoch 12] train_loss=0.7982, train_acc=0.969, val_loss=0.9757, val_acc=0.884\n",
            "[GRU][Epoch 13] train_loss=0.7891, train_acc=0.974, val_loss=0.9474, val_acc=0.909\n",
            "✅ Saved weights-only: /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_best.pt\n",
            "✅ Saved norm       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_norm.npz\n",
            "✅ Saved meta       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_meta.json\n",
            "[GRU][Epoch 14] train_loss=0.7800, train_acc=0.973, val_loss=0.9698, val_acc=0.896\n",
            "[GRU][Epoch 15] train_loss=0.7571, train_acc=0.982, val_loss=0.9664, val_acc=0.896\n",
            "[GRU][Epoch 16] train_loss=0.7498, train_acc=0.984, val_loss=0.9839, val_acc=0.896\n",
            "[GRU][Epoch 17] train_loss=0.7494, train_acc=0.986, val_loss=0.9607, val_acc=0.902\n",
            "[GRU][Epoch 18] train_loss=0.7282, train_acc=0.986, val_loss=0.9435, val_acc=0.915\n",
            "✅ Saved weights-only: /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_best.pt\n",
            "✅ Saved norm       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_norm.npz\n",
            "✅ Saved meta       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_meta.json\n",
            "[GRU][Epoch 19] train_loss=0.7112, train_acc=0.992, val_loss=0.9069, val_acc=0.921\n",
            "✅ Saved weights-only: /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_best.pt\n",
            "✅ Saved norm       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_norm.npz\n",
            "✅ Saved meta       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_meta.json\n",
            "[GRU][Epoch 20] train_loss=0.7015, train_acc=0.992, val_loss=0.9151, val_acc=0.909\n",
            "[GRU][Epoch 21] train_loss=0.6993, train_acc=0.996, val_loss=0.9201, val_acc=0.909\n",
            "[GRU][Epoch 22] train_loss=0.7041, train_acc=0.992, val_loss=0.9236, val_acc=0.909\n",
            "[GRU][Epoch 23] train_loss=0.6988, train_acc=0.992, val_loss=0.9165, val_acc=0.915\n",
            "[GRU][Epoch 24] train_loss=0.6877, train_acc=0.997, val_loss=0.9172, val_acc=0.909\n",
            "[GRU][Epoch 25] train_loss=0.6886, train_acc=0.995, val_loss=0.9094, val_acc=0.921\n",
            "[GRU][Epoch 26] train_loss=0.6905, train_acc=0.996, val_loss=0.9137, val_acc=0.909\n",
            "[GRU][Epoch 27] train_loss=0.6857, train_acc=0.999, val_loss=0.9084, val_acc=0.915\n",
            "[GRU][Epoch 28] train_loss=0.6882, train_acc=0.995, val_loss=0.9014, val_acc=0.927\n",
            "✅ Saved weights-only: /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_best.pt\n",
            "✅ Saved norm       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_norm.npz\n",
            "✅ Saved meta       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_meta.json\n",
            "[GRU][Epoch 29] train_loss=0.6841, train_acc=0.996, val_loss=0.8998, val_acc=0.927\n",
            "[GRU][Epoch 30] train_loss=0.6786, train_acc=1.000, val_loss=0.9040, val_acc=0.909\n",
            "[GRU][Epoch 31] train_loss=0.6790, train_acc=0.995, val_loss=0.9007, val_acc=0.915\n",
            "[GRU][Epoch 32] train_loss=0.6775, train_acc=0.997, val_loss=0.9002, val_acc=0.921\n",
            "[GRU][Epoch 33] train_loss=0.6825, train_acc=0.995, val_loss=0.9026, val_acc=0.915\n",
            "[GRU][Epoch 34] train_loss=0.6769, train_acc=0.999, val_loss=0.8994, val_acc=0.915\n",
            "[GRU][Epoch 35] train_loss=0.6758, train_acc=1.000, val_loss=0.8990, val_acc=0.921\n",
            "[GRU][Epoch 36] train_loss=0.6782, train_acc=0.999, val_loss=0.9003, val_acc=0.921\n",
            "[GRU][Epoch 37] train_loss=0.6803, train_acc=0.999, val_loss=0.9004, val_acc=0.921\n",
            "[GRU][Epoch 38] train_loss=0.6824, train_acc=0.995, val_loss=0.8987, val_acc=0.921\n",
            "[GRU][Epoch 39] train_loss=0.6770, train_acc=0.999, val_loss=0.8994, val_acc=0.915\n",
            "[GRU][Epoch 40] train_loss=0.6752, train_acc=0.999, val_loss=0.9000, val_acc=0.909\n",
            "\n",
            "[GRU][Final] Best val_acc=0.927\n",
            "[GRU][Final] Test loss=0.9218, Test acc=0.892\n",
            "✅ Best weights at: /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/gru_best.pt\n",
            "\n",
            "[TCN][Epoch 01] train_loss=2.8253, train_acc=0.177, val_loss=2.4069, val_acc=0.341\n",
            "✅ Saved weights-only: /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_best.pt\n",
            "✅ Saved norm       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_norm.npz\n",
            "✅ Saved meta       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_meta.json\n",
            "[TCN][Epoch 02] train_loss=1.9653, train_acc=0.501, val_loss=1.6882, val_acc=0.579\n",
            "✅ Saved weights-only: /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_best.pt\n",
            "✅ Saved norm       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_norm.npz\n",
            "✅ Saved meta       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_meta.json\n",
            "[TCN][Epoch 03] train_loss=1.4445, train_acc=0.716, val_loss=1.2804, val_acc=0.756\n",
            "✅ Saved weights-only: /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_best.pt\n",
            "✅ Saved norm       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_norm.npz\n",
            "✅ Saved meta       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_meta.json\n",
            "[TCN][Epoch 04] train_loss=1.1904, train_acc=0.815, val_loss=1.1512, val_acc=0.799\n",
            "✅ Saved weights-only: /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_best.pt\n",
            "✅ Saved norm       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_norm.npz\n",
            "✅ Saved meta       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_meta.json\n",
            "[TCN][Epoch 05] train_loss=1.0391, train_acc=0.871, val_loss=1.0602, val_acc=0.835\n",
            "✅ Saved weights-only: /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_best.pt\n",
            "✅ Saved norm       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_norm.npz\n",
            "✅ Saved meta       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_meta.json\n",
            "[TCN][Epoch 06] train_loss=0.9699, train_acc=0.913, val_loss=1.0860, val_acc=0.841\n",
            "✅ Saved weights-only: /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_best.pt\n",
            "✅ Saved norm       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_norm.npz\n",
            "✅ Saved meta       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_meta.json\n",
            "[TCN][Epoch 07] train_loss=0.8939, train_acc=0.939, val_loss=0.9742, val_acc=0.896\n",
            "✅ Saved weights-only: /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_best.pt\n",
            "✅ Saved norm       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_norm.npz\n",
            "✅ Saved meta       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_meta.json\n",
            "[TCN][Epoch 08] train_loss=0.8612, train_acc=0.948, val_loss=0.9670, val_acc=0.884\n",
            "[TCN][Epoch 09] train_loss=0.8316, train_acc=0.950, val_loss=0.9474, val_acc=0.896\n",
            "[TCN][Epoch 10] train_loss=0.8083, train_acc=0.965, val_loss=0.8749, val_acc=0.933\n",
            "✅ Saved weights-only: /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_best.pt\n",
            "✅ Saved norm       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_norm.npz\n",
            "✅ Saved meta       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_meta.json\n",
            "[TCN][Epoch 11] train_loss=0.7957, train_acc=0.957, val_loss=0.9177, val_acc=0.902\n",
            "[TCN][Epoch 12] train_loss=0.7800, train_acc=0.965, val_loss=0.9788, val_acc=0.878\n",
            "[TCN][Epoch 13] train_loss=0.7752, train_acc=0.962, val_loss=0.8312, val_acc=0.933\n",
            "[TCN][Epoch 14] train_loss=0.7618, train_acc=0.977, val_loss=0.8901, val_acc=0.933\n",
            "[TCN][Epoch 15] train_loss=0.7280, train_acc=0.984, val_loss=0.8817, val_acc=0.909\n",
            "[TCN][Epoch 16] train_loss=0.7151, train_acc=0.983, val_loss=0.8437, val_acc=0.939\n",
            "✅ Saved weights-only: /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_best.pt\n",
            "✅ Saved norm       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_norm.npz\n",
            "✅ Saved meta       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_meta.json\n",
            "[TCN][Epoch 17] train_loss=0.7023, train_acc=0.991, val_loss=0.8376, val_acc=0.933\n",
            "[TCN][Epoch 18] train_loss=0.7009, train_acc=0.990, val_loss=0.8482, val_acc=0.915\n",
            "[TCN][Epoch 19] train_loss=0.6958, train_acc=0.988, val_loss=0.8128, val_acc=0.939\n",
            "[TCN][Epoch 20] train_loss=0.6867, train_acc=0.992, val_loss=0.8091, val_acc=0.939\n",
            "[TCN][Epoch 21] train_loss=0.6803, train_acc=0.993, val_loss=0.8110, val_acc=0.939\n",
            "[TCN][Epoch 22] train_loss=0.6909, train_acc=0.990, val_loss=0.8080, val_acc=0.945\n",
            "✅ Saved weights-only: /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_best.pt\n",
            "✅ Saved norm       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_norm.npz\n",
            "✅ Saved meta       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_meta.json\n",
            "[TCN][Epoch 23] train_loss=0.6772, train_acc=0.996, val_loss=0.8131, val_acc=0.933\n",
            "[TCN][Epoch 24] train_loss=0.6782, train_acc=0.992, val_loss=0.8171, val_acc=0.933\n",
            "[TCN][Epoch 25] train_loss=0.6792, train_acc=0.990, val_loss=0.8027, val_acc=0.945\n",
            "[TCN][Epoch 26] train_loss=0.6713, train_acc=0.997, val_loss=0.8047, val_acc=0.933\n",
            "[TCN][Epoch 27] train_loss=0.6728, train_acc=0.995, val_loss=0.8058, val_acc=0.933\n",
            "[TCN][Epoch 28] train_loss=0.6754, train_acc=0.990, val_loss=0.7924, val_acc=0.951\n",
            "✅ Saved weights-only: /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_best.pt\n",
            "✅ Saved norm       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_norm.npz\n",
            "✅ Saved meta       : /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_meta.json\n",
            "[TCN][Epoch 29] train_loss=0.6750, train_acc=0.992, val_loss=0.7925, val_acc=0.945\n",
            "[TCN][Epoch 30] train_loss=0.6663, train_acc=0.995, val_loss=0.7894, val_acc=0.933\n",
            "[TCN][Epoch 31] train_loss=0.6669, train_acc=0.996, val_loss=0.7848, val_acc=0.939\n",
            "[TCN][Epoch 32] train_loss=0.6685, train_acc=0.995, val_loss=0.7846, val_acc=0.945\n",
            "[TCN][Epoch 33] train_loss=0.6604, train_acc=1.000, val_loss=0.7833, val_acc=0.939\n",
            "[TCN][Epoch 34] train_loss=0.6689, train_acc=0.996, val_loss=0.7859, val_acc=0.945\n",
            "[TCN][Epoch 35] train_loss=0.6693, train_acc=0.993, val_loss=0.7824, val_acc=0.933\n",
            "[TCN][Epoch 36] train_loss=0.6668, train_acc=0.992, val_loss=0.7800, val_acc=0.939\n",
            "[TCN][Epoch 37] train_loss=0.6677, train_acc=0.996, val_loss=0.7809, val_acc=0.933\n",
            "[TCN][Epoch 38] train_loss=0.6670, train_acc=0.996, val_loss=0.7802, val_acc=0.939\n",
            "[TCN][Epoch 39] train_loss=0.6658, train_acc=0.993, val_loss=0.7806, val_acc=0.933\n",
            "[TCN][Epoch 40] train_loss=0.6606, train_acc=0.997, val_loss=0.7794, val_acc=0.939\n",
            "\n",
            "[TCN][Final] Best val_acc=0.951\n",
            "[TCN][Final] Test loss=0.7920, Test acc=0.952\n",
            "✅ Best weights at: /content/drive/MyDrive/cv-medislr/data/preprocessed/model_weights/1D/tcn_best.pt\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### demo용 데이터 만들기"
      ],
      "metadata": {
        "id": "UTnJ8y1RAZxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# =========================\n",
        "# 경로 설정\n",
        "# =========================\n",
        "CACHE_DIR = \"/content/drive/MyDrive/cv-medislr/data/preprocessed/tensors/1D\"\n",
        "SAVE_DIR  = \"/content/drive/MyDrive/cv-medislr/data/samples/1D\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "SEED = 42\n",
        "K = 20\n",
        "\n",
        "data_npz  = os.path.join(CACHE_DIR, \"data_HANDS_T16_seed42.npz\")\n",
        "split_npz = os.path.join(CACHE_DIR, \"split_HANDS_T16_seed42.npz\")\n",
        "meta_json = os.path.join(CACHE_DIR, \"meta_HANDS_T16_seed42.json\")\n",
        "\n",
        "assert os.path.exists(data_npz),  f\"❌ {data_npz} 없음\"\n",
        "assert os.path.exists(split_npz), f\"❌ {split_npz} 없음\"\n",
        "assert os.path.exists(meta_json), f\"❌ {meta_json} 없음\"\n",
        "\n",
        "print(\"✅ Using cache files:\")\n",
        "print(\" data :\", data_npz)\n",
        "print(\" split:\", split_npz)\n",
        "print(\" meta :\", meta_json)\n",
        "\n",
        "# =========================\n",
        "# 1. 로드\n",
        "# =========================\n",
        "pack = np.load(data_npz)\n",
        "X = pack[\"X\"].astype(np.float32)   # (N,T,D)\n",
        "y = pack[\"y\"].astype(np.int64)     # (N,)\n",
        "\n",
        "split = np.load(split_npz)\n",
        "test_idx = split[\"test_idx\"].astype(np.int64)\n",
        "\n",
        "with open(meta_json, \"r\", encoding=\"utf-8\") as f:\n",
        "    meta = json.load(f)\n",
        "\n",
        "label2idx = meta[\"label2idx\"]\n",
        "idx2label = {int(v): k for k, v in label2idx.items()}\n",
        "\n",
        "print(f\"Total test samples: {len(test_idx)}\")\n",
        "\n",
        "# =========================\n",
        "# 2. test에서 20개 고정 샘플링\n",
        "# =========================\n",
        "rng = np.random.default_rng(SEED)\n",
        "k = min(K, len(test_idx))\n",
        "\n",
        "picked_idx = rng.choice(test_idx, size=k, replace=False).astype(np.int64)\n",
        "\n",
        "X_demo = X[picked_idx]   # (k,T,D)\n",
        "y_demo = y[picked_idx]   # (k,)\n",
        "\n",
        "# =========================\n",
        "# 3. 저장\n",
        "# =========================\n",
        "out_npz = os.path.join(SAVE_DIR, f\"demo_test{k}_HANDS_T16_seed{SEED}.npz\")\n",
        "np.savez_compressed(\n",
        "    out_npz,\n",
        "    X_demo=X_demo,\n",
        "    y_demo=y_demo,\n",
        "    orig_idx=picked_idx\n",
        ")\n",
        "\n",
        "out_json = os.path.join(SAVE_DIR, f\"demo_test{k}_HANDS_T16_seed{SEED}.json\")\n",
        "out_meta = {\n",
        "    \"source_cache_dir\": CACHE_DIR,\n",
        "    \"k\": int(k),\n",
        "    \"seed\": int(SEED),\n",
        "    \"target_len\": int(meta[\"target_len\"]),\n",
        "    \"input_dim\": int(meta[\"input_dim\"]),\n",
        "    \"num_classes\": int(meta[\"num_classes\"]),\n",
        "    \"label2idx\": label2idx,\n",
        "    \"picked_orig_idx\": picked_idx.tolist(),\n",
        "    \"picked_labels_text\": [idx2label[int(c)] for c in y_demo.tolist()],\n",
        "}\n",
        "\n",
        "with open(out_json, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(out_meta, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"✅ Demo samples saved:\")\n",
        "print(\" \", out_npz)\n",
        "print(\" \", out_json)\n",
        "print(\" X_demo:\", X_demo.shape, \"y_demo:\", y_demo.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqAYp2IqAcfl",
        "outputId": "3b2a1a40-73b9-41b2-c688-d7493b29636c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Using cache files:\n",
            " data : /content/drive/MyDrive/cv-medislr/data/preprocessed/tensors/1D/data_HANDS_T16_seed42.npz\n",
            " split: /content/drive/MyDrive/cv-medislr/data/preprocessed/tensors/1D/split_HANDS_T16_seed42.npz\n",
            " meta : /content/drive/MyDrive/cv-medislr/data/preprocessed/tensors/1D/meta_HANDS_T16_seed42.json\n",
            "Total test samples: 166\n",
            "✅ Demo samples saved:\n",
            "  /content/drive/MyDrive/cv-medislr/data/samples/1D/demo_test20_HANDS_T16_seed42.npz\n",
            "  /content/drive/MyDrive/cv-medislr/data/samples/1D/demo_test20_HANDS_T16_seed42.json\n",
            " X_demo: (20, 16, 336) y_demo: (20,)\n"
          ]
        }
      ]
    }
  ]
}